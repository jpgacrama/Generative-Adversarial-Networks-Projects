{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter03.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM5ZM+zeSWfMQwPvA9gJ6I7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Md6klvUXMtMc"},"source":["# CHAPTER 3: Face Aging"]},{"cell_type":"markdown","metadata":{"id":"dL05Dtrp5zam"},"source":["## Pre-requisites"]},{"cell_type":"markdown","metadata":{"id":"IWfY0Le6MyKA"},"source":["Import OS functions"]},{"cell_type":"code","metadata":{"id":"izlE90zVMruZ"},"source":["import glob\n","import os\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pV8YTRKM95j"},"source":["Mounting Google Drive and downloading needed data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vrjEG4sHNAsU","executionInfo":{"status":"ok","timestamp":1635477425762,"user_tz":-480,"elapsed":18823,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}},"outputId":"96e3e6c4-fb45-4c72-cf3c-3e5742685885"},"source":["from google.colab import drive\n","\n","# Mounting Google Drive\n","drive.mount('/drive')\n","os.chdir('/drive/My Drive/Colab/GenerativeAdversarialNetworks/Chapter03')\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","# # Download Dataset\n","# !wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar -P ./data\n","# !tar -xvf ./data/wiki_crop.tar -C ./data\n","\n","# Clear any logs from previous runs\n","# !rm -rf ./logs/ "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"4vTaECgSzMjL"},"source":["Importing the rest of the needed libraries"]},{"cell_type":"code","metadata":{"id":"2UJUW2BKzXW6","executionInfo":{"status":"ok","timestamp":1635485505066,"user_tz":-480,"elapsed":410,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["from datetime import datetime\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import pickle\n","from keras import Input, Model\n","from keras.applications.inception_resnet_v2 import InceptionResNetV2\n","from keras.callbacks import TensorBoard\n","from keras.layers import Conv2D, Flatten, Dense, BatchNormalization, Reshape, concatenate, LeakyReLU, Lambda\n","from tensorflow.keras import backend as K\n","from keras.layers import Activation, UpSampling2D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from keras_preprocessing import image\n","from scipy.io import loadmat\n","from tqdm import tqdm\n","\n","# Fixed problems with Error #15: Initializing libiomp5md.dll, but found libiomp5 already initialized.\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2pizDQJEzZji"},"source":["Clear the screen"]},{"cell_type":"code","metadata":{"id":"m5IW_nLYzbp3","executionInfo":{"status":"ok","timestamp":1635485506018,"user_tz":-480,"elapsed":583,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def clear():\n","    # for windows\n","    if os.name == 'nt':\n","        _ = os.system('cls')\n","  \n","    # for mac and linux(here, os.name is 'posix')\n","    else:\n","        _ = os.system('clear')"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RgPpqkTg54id"},"source":["## Build the Encoder, Generator and Discriminator, and the complete Facial Recognition Models"]},{"cell_type":"markdown","metadata":{"id":"HrZIq93Fzf6p"},"source":["Build the Encoder"]},{"cell_type":"code","metadata":{"id":"TdcPLMclzhav","executionInfo":{"status":"ok","timestamp":1635485506019,"user_tz":-480,"elapsed":24,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def build_encoder():\n","    \"\"\"\n","    Encoder Network\n","    \"\"\"\n","    input_layer = Input(shape=(64, 64, 3))\n","\n","    # 1st Convolutional Block\n","    enc = Conv2D(filters=32, kernel_size=5, strides=2, padding='same')(input_layer)\n","    # enc = BatchNormalization()(enc)\n","    enc = LeakyReLU(alpha=0.2)(enc)\n","\n","    # 2nd Convolutional Block\n","    enc = Conv2D(filters=64, kernel_size=5, strides=2, padding='same')(enc)\n","    enc = BatchNormalization()(enc)\n","    enc = LeakyReLU(alpha=0.2)(enc)\n","\n","    # 3rd Convolutional Block\n","    enc = Conv2D(filters=128, kernel_size=5, strides=2, padding='same')(enc)\n","    enc = BatchNormalization()(enc)\n","    enc = LeakyReLU(alpha=0.2)(enc)\n","\n","    # 4th Convolutional Block\n","    enc = Conv2D(filters=256, kernel_size=5, strides=2, padding='same')(enc)\n","    enc = BatchNormalization()(enc)\n","    enc = LeakyReLU(alpha=0.2)(enc)\n","\n","    # Flatten layer\n","    enc = Flatten()(enc)\n","\n","    # 1st Fully Connected Layer\n","    enc = Dense(4096)(enc)\n","    enc = BatchNormalization()(enc)\n","    enc = LeakyReLU(alpha=0.2)(enc)\n","\n","    # Second Fully Connected Layer\n","    enc = Dense(100)(enc)\n","\n","    # Create a model\n","    model = Model(inputs=[input_layer], outputs=[enc])\n","    return model\n"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qWDfDSemziTY"},"source":["Build the Generator"]},{"cell_type":"code","metadata":{"id":"8aznwJCdzlY0","executionInfo":{"status":"ok","timestamp":1635485506019,"user_tz":-480,"elapsed":24,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def build_generator():\n","    \"\"\"\n","    Create a Generator Model with hyperparameters values defined as follows\n","    \"\"\"\n","    latent_dims = 100\n","    num_classes = 6\n","\n","    input_z_noise = Input(shape=(latent_dims,))\n","    input_label = Input(shape=(num_classes,))\n","\n","    x = concatenate([input_z_noise, input_label])\n","\n","    x = Dense(2048, input_dim=latent_dims + num_classes)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.2)(x)\n","\n","    x = Dense(256 * 8 * 8)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","    x = Dropout(0.2)(x)\n","\n","    x = Reshape((8, 8, 256))(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(filters=128, kernel_size=5, padding='same')(x)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(filters=64, kernel_size=5, padding='same')(x)\n","    x = BatchNormalization(momentum=0.8)(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = UpSampling2D(size=(2, 2))(x)\n","    x = Conv2D(filters=3, kernel_size=5, padding='same')(x)\n","    x = Activation('tanh')(x)\n","\n","    model = Model(inputs=[input_z_noise, input_label], outputs=[x])\n","    return model\n"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5TNBPBlI0cWh"},"source":["Build the Discriminator"]},{"cell_type":"code","metadata":{"id":"nzW_ukKz0eyF","executionInfo":{"status":"ok","timestamp":1635485506020,"user_tz":-480,"elapsed":24,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def build_discriminator():\n","    \"\"\"\n","    Create a Discriminator Model with hyperparameters values defined as follows\n","    \"\"\"\n","    input_shape = (64, 64, 3)\n","    label_shape = (6,)\n","    image_input = Input(shape=input_shape)\n","    label_input = Input(shape=label_shape)\n","\n","    x = Conv2D(64, kernel_size=3, strides=2, padding='same')(image_input)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    label_input1 = Lambda(expand_label_input)(label_input)\n","    x = concatenate([x, label_input1], axis=3)\n","\n","    x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = Conv2D(512, kernel_size=3, strides=2, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU(alpha=0.2)(x)\n","\n","    x = Flatten()(x)\n","    x = Dense(1, activation='sigmoid')(x)\n","\n","    model = Model(inputs=[image_input, label_input], outputs=[x])\n","    return model\n"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ckwYdWG75dRR"},"source":["Build the Facial Recognition Model"]},{"cell_type":"code","metadata":{"id":"FGr3qsja5qYB","executionInfo":{"status":"ok","timestamp":1635485506020,"user_tz":-480,"elapsed":23,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def build_fr_model(input_shape):\n","    resent_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n","    image_input = resent_model.input\n","    x = resent_model.layers[-1].output\n","    out = Dense(128)(x)\n","    embedder_model = Model(inputs=[image_input], outputs=[out])\n","\n","    input_layer = Input(shape=input_shape)\n","\n","    x = embedder_model(input_layer)\n","    output = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x)\n","\n","    model = Model(inputs=[input_layer], outputs=[output])\n","    return model"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZXxb-XEv5Wk7"},"source":["Build the Combined Face Recognition Network containing the Generator and Encoder"]},{"cell_type":"code","metadata":{"id":"oTO3O9Z25aAM","executionInfo":{"status":"ok","timestamp":1635485506021,"user_tz":-480,"elapsed":23,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def build_fr_combined_network(encoder, generator, fr_model):\n","    input_image = Input(shape=(64, 64, 3))\n","    input_label = Input(shape=(6,))\n","\n","    latent0 = encoder(input_image)\n","\n","    gen_images = generator([latent0, input_label])\n","\n","    fr_model.trainable = False\n","\n","    resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=2, width_factor=2,\n","                                                      data_format='channels_last'))(gen_images)\n","    embeddings = fr_model(resized_images)\n","\n","    model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n","    return model\n"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-PSqKocB6I8t"},"source":["## Helper functions"]},{"cell_type":"markdown","metadata":{"id":"4JFbUKDw6LJg"},"source":["Expand the Label Inputs"]},{"cell_type":"code","metadata":{"id":"t8yF5Lez6Lk3","executionInfo":{"status":"ok","timestamp":1635485506021,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def expand_label_input(x):\n","    x = K.expand_dims(x, axis=1)\n","    x = K.expand_dims(x, axis=1)\n","    x = K.tile(x, [1, 32, 32, 1])\n","    return x"],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"29jGtf_a6Slg"},"source":["Image Resizer"]},{"cell_type":"code","metadata":{"id":"UJLNpUd06UGk","executionInfo":{"status":"ok","timestamp":1635485506021,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def build_image_resizer():\n","    input_layer = Input(shape=(64, 64, 3))\n","\n","    resized_images = Lambda(lambda x: K.resize_images(x, height_factor=3, width_factor=3,\n","                                                      data_format='channels_last'))(input_layer)\n","\n","    model = Model(inputs=[input_layer], outputs=[resized_images])\n","    return model"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dBElHc5b6Vem"},"source":["Age Calculator"]},{"cell_type":"code","metadata":{"id":"WKK_rlxZ6Wtk","executionInfo":{"status":"ok","timestamp":1635485506022,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def calculate_age(taken, dob):\n","    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n","\n","    if birth.month < 7:\n","        return taken - birth.year\n","    else:\n","        return taken - birth.year - 1"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5HUVKyNI6ZBd"},"source":["Data Loader"]},{"cell_type":"code","metadata":{"id":"gQQt2GQS6aKx","executionInfo":{"status":"ok","timestamp":1635485506022,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def load_data(wiki_dir, dataset='wiki'):\n","    # Load the wiki.mat file\n","    meta = loadmat(os.path.join(wiki_dir, f\"{dataset}.mat\"))\n","\n","    # Load the list of all files\n","    full_path = meta[dataset][0, 0][\"full_path\"][0]\n","\n","    # List of Matlab serial date number\n","    dob = meta[dataset][0, 0][\"dob\"][0]\n","\n","    # List of years when photo was taken\n","    photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]  # year\n","\n","    # Calculate age for all dobs\n","    age = [calculate_age(photo_taken[i], dob[i]) for i in range(len(dob))]\n","\n","    # Create a list of tuples containing a pair of an image path and age\n","    images = []\n","    age_list = []\n","    for index, image_path in enumerate(full_path):\n","        images.append(image_path[0])\n","        age_list.append(age[index])\n","\n","    # Return a list of all images and respective age\n","    return images, age_list\n"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQ4WKlKq6dKO"},"source":["Splitting Ages to Specific Categories"]},{"cell_type":"code","metadata":{"id":"j5AKXNwU6iW4","executionInfo":{"status":"ok","timestamp":1635485506022,"user_tz":-480,"elapsed":21,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def age_to_category(age_list):\n","    age_list1 = []\n","\n","    for age in age_list:\n","        if 0 < age <= 18:\n","            age_category = 0\n","        elif 18 < age <= 29:\n","            age_category = 1\n","        elif 29 < age <= 39:\n","            age_category = 2\n","        elif 39 < age <= 49:\n","            age_category = 3\n","        elif 49 < age <= 59:\n","            age_category = 4\n","        elif age >= 60:\n","            age_category = 5\n","\n","        age_list1.append(age_category)\n","\n","    return age_list1\n"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hWx9fwYq6mmp"},"source":["Image Loader"]},{"cell_type":"code","metadata":{"id":"cHh5G8ZY6ntm","executionInfo":{"status":"ok","timestamp":1635485506023,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def load_images(data_dir, image_paths, image_shape):\n","    images = None\n","    number_of_images = len(image_paths)\n","    pbar = tqdm(total=number_of_images) # Init pbar\n","\n","    print(f'Loading {number_of_images} images')\n","    for i, image_path in enumerate(image_paths):\n","        pbar.update(n=1) # Increments counter\n","        try:\n","            # Load image\n","            loaded_image = image.load_img(os.path.join(data_dir, image_path), target_size=image_shape)\n","\n","            # Convert PIL image to numpy ndarray\n","            loaded_image = image.img_to_array(loaded_image)\n","\n","            # Add another dimension (Add batch dimension)\n","            loaded_image = np.expand_dims(loaded_image, axis=0)\n","\n","            # Concatenate all images into one tensor\n","            if images is None:\n","                images = loaded_image\n","            else:\n","                images = np.concatenate([images, loaded_image], axis=0)\n","        except Exception as e:\n","            print(f\"Error at {i} with Exception {e}\")\n","\n","    print('Finished loading all images')\n","    return images\n"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j5h6uqV_6pVj"},"source":["Calculator for Euclidean Distance Loss"]},{"cell_type":"code","metadata":{"id":"CuGTcAH26sO_","executionInfo":{"status":"ok","timestamp":1635485506023,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def euclidean_distance_loss(y_true, y_pred):\n","    \"\"\"\n","    Euclidean distance loss\n","    https://en.wikipedia.org/wiki/Euclidean_distance\n","    :param y_true: TensorFlow/Theano tensor\n","    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n","    :return: float\n","    \"\"\"\n","    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EIkbH5yg6vWY"},"source":["Log Writer"]},{"cell_type":"code","metadata":{"id":"ZY4K_Jjk6wWN","executionInfo":{"status":"ok","timestamp":1635485506024,"user_tz":-480,"elapsed":22,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def write_log(callback, name, value, batch_no):\n","    writer = tf.summary.create_file_writer(callback.log_dir)\n","    with writer.as_default():\n","        tf.summary.scalar(name, value, step=batch_no)"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1EE8E3NQ7Flr"},"source":["RGB image Saver"]},{"cell_type":"code","metadata":{"id":"PWQjWBqb7Ivj","executionInfo":{"status":"ok","timestamp":1635485506025,"user_tz":-480,"elapsed":23,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["def save_rgb_img(img, path):\n","    \"\"\"\n","    Save an rgb image\n","    \"\"\"\n","    fig = plt.figure()\n","    ax = fig.add_subplot(1, 1, 1)\n","    ax.imshow(img)\n","    ax.axis(\"off\")\n","    ax.set_title(\"Image\")\n","\n","    plt.savefig(path)\n","    plt.close()"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FDrQyATa7OFb"},"source":["## Putting it All together"]},{"cell_type":"markdown","metadata":{"id":"7VDXQv0p7Rmj"},"source":["### Define hyperparameters\n"]},{"cell_type":"markdown","metadata":{"id":"ownn2OZ_8vY1"},"source":["Don't forget to set the boolean values on what to train"]},{"cell_type":"code","metadata":{"id":"s1jjzWwa7VHr","executionInfo":{"status":"ok","timestamp":1635485506026,"user_tz":-480,"elapsed":24,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["data_dir = \"data\"\n","wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n","epochs = 500\n","batch_size = 2\n","image_shape = (64, 64, 3)\n","z_shape = 100\n","TRAIN_GAN = True\n","TRAIN_ENCODER = False\n","TRAIN_GAN_WITH_FR = False\n","fr_image_shape = (192, 192, 3)"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NlKTqc3x7fgO"},"source":["### Clears the screen"]},{"cell_type":"code","metadata":{"id":"GpCTsqYT7abp","executionInfo":{"status":"ok","timestamp":1635485506027,"user_tz":-480,"elapsed":24,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["clear()"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E7Msqwgz7ij5"},"source":["### Define optimizers"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ll4D1X3Q7lb5","executionInfo":{"status":"ok","timestamp":1635485506028,"user_tz":-480,"elapsed":25,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}},"outputId":"e8109c10-3597-4d85-e68d-bae5c935d851"},"source":["dis_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n","gen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n","adversarial_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"]}]},{"cell_type":"markdown","metadata":{"id":"PJjYJv3l7oJv"},"source":["### Build and compile the networks"]},{"cell_type":"code","metadata":{"id":"r0PaKRM57qNb","executionInfo":{"status":"ok","timestamp":1635485506554,"user_tz":-480,"elapsed":544,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["# Build and compile the discriminator network\n","discriminator = build_discriminator()\n","discriminator.compile(loss=['binary_crossentropy'], optimizer=dis_optimizer)\n","\n","# Build and compile the generator network\n","generator = build_generator()\n","generator.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)\n","\n","# Build and compile the adversarial model\n","discriminator.trainable = False\n","input_z_noise = Input(shape=(100,))\n","input_label = Input(shape=(6,))\n","recons_images = generator([input_z_noise, input_label])\n","valid = discriminator([recons_images, input_label])\n","adversarial_model = Model(inputs=[input_z_noise, input_label], outputs=[valid])\n","adversarial_model.compile(loss=['binary_crossentropy'], optimizer=gen_optimizer)"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fH-kQwbY7vi_"},"source":["### Creating the Tensorboard"]},{"cell_type":"code","metadata":{"id":"HnRFmBLV7xm6","executionInfo":{"status":"ok","timestamp":1635485506555,"user_tz":-480,"elapsed":4,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}}},"source":["tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time.time()))\n","tensorboard.set_model(generator)\n","tensorboard.set_model(discriminator)"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPsAwIWf70Va"},"source":["### Load the Dataset"]},{"cell_type":"markdown","metadata":{"id":"ehmzV1Cynty0"},"source":["#### Load from Pickle"]},{"cell_type":"code","metadata":{"id":"kLjnEfNInwTc"},"source":["with open('pickle_objects.pkl', 'rb') as pickle_in:\n","     # Deserialize class loaded_images\n","     loaded_images = pickle.load(pickle_in)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8qxOM8U72Ly","executionInfo":{"status":"ok","timestamp":1635485508695,"user_tz":-480,"elapsed":2143,"user":{"displayName":"Jonas Gacrama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghgh7Xc1fCUmRIyX8mhx4l4Kn0168rxpI_6Bpc6=s64","userId":"07582691040132947086"}},"outputId":"d1aad822-a185-4383-9e53-ab33b7543632"},"source":["images, age_list = load_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n","age_cat = age_to_category(age_list)\n","final_age_cat = np.reshape(np.array(age_cat), [len(age_cat), 1])\n","classes = len(set(age_cat))\n","y = to_categorical(final_age_cat, num_classes=len(set(age_cat)))"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images: 62328\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZtM6AMILebG-","outputId":"aabccc9f-c338-4fdb-c200-3a254da6e95c"},"source":["loaded_images = load_images(wiki_dir, images, (image_shape[0], image_shape[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 26388/62328 [1:55:14<5:58:05,  1.67it/s]"]}]},{"cell_type":"markdown","metadata":{"id":"WD1R_LienP72"},"source":["####Pickling Data for future use"]},{"cell_type":"code","metadata":{"id":"MxCKOf0nnTuK"},"source":["with open('pickle_objects.pkl', 'wb') as pickle_out:\n","    # Serialize Loaded Images\n","    pickle.dump(loaded_images, pickle_out)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yEr90YVn74f8"},"source":["### Implement Label Smoothing"]},{"cell_type":"code","metadata":{"id":"q_oGShB_7747"},"source":["real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n","fake_labels = np.zeros((batch_size, 1), dtype=np.float32) * 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VxJSKCGM8GDv"},"source":["### Train GAN"]},{"cell_type":"code","metadata":{"id":"Bd6AZvIf8H3J"},"source":["if TRAIN_GAN:\n","    print(f'\\n\\n #################### TRAINING GAN ####################\\n\\n')\n","    for epoch in range(epochs):\n","        print(f\"\\nEpoch: {epoch + 1} out of {len(range(epochs))}\")\n","\n","        gen_losses = []\n","        dis_losses = []\n","\n","        number_of_batches = int(len(loaded_images) / batch_size)\n","        for index in range(number_of_batches):\n","            print(f\"\\tBatch: {index + 1} out of {len(range(number_of_batches))}\\n\")\n","\n","            images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n","            images_batch = images_batch / 127.5 - 1.0\n","            images_batch = images_batch.astype(np.float32)\n","\n","            y_batch = y[index * batch_size:(index + 1) * batch_size]\n","            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n","\n","            \"\"\"\n","            Train the discriminator network\n","            \"\"\"\n","\n","            # Generate fake images\n","            initial_recon_images = generator.predict_on_batch([z_noise, y_batch])\n","\n","            d_loss_real = discriminator.train_on_batch([images_batch, y_batch], real_labels)\n","            d_loss_fake = discriminator.train_on_batch([initial_recon_images, y_batch], fake_labels)\n","\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","            print(f\"\\td_loss:{d_loss}\")\n","\n","            \"\"\"\n","            Train the generator network\n","            \"\"\"\n","\n","            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_shape))\n","            random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n","            random_labels = to_categorical(random_labels, 6)\n","\n","            g_loss = adversarial_model.train_on_batch([z_noise2, random_labels], [1] * batch_size)\n","\n","            print(f\"\\tg_loss:{g_loss}\")\n","\n","            gen_losses.append(g_loss)\n","            dis_losses.append(d_loss)\n","\n","        # Write losses to Tensorboard\n","        write_log(tensorboard, 'g_loss', np.mean(gen_losses), epoch)\n","        write_log(tensorboard, 'd_loss', np.mean(dis_losses), epoch)\n","\n","        \"\"\"\n","        Generate images after every 10th epoch\n","        \"\"\"\n","        if epoch % 10 == 0:\n","            images_batch = loaded_images[0:batch_size]\n","            images_batch = images_batch / 127.5 - 1.0\n","            images_batch = images_batch.astype(np.float32)\n","\n","            y_batch = y[0:batch_size]\n","            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n","\n","            gen_images = generator.predict_on_batch([z_noise, y_batch])\n","\n","            for i, img in enumerate(gen_images[:5]):\n","                save_rgb_img(img, path=\"results/img_{}_{}.png\".format(epoch, i))\n","\n","    # Save networks\n","    try:\n","        generator.save_weights(\"generator.h5\")\n","        discriminator.save_weights(\"discriminator.h5\")\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ojHCTwM18SoD"},"source":["### Train the Encoder"]},{"cell_type":"code","metadata":{"id":"Fxe_05ib8UkY"},"source":["if TRAIN_ENCODER:\n","    # Build and compile encoder\n","    encoder = build_encoder()\n","    encoder.compile(loss=euclidean_distance_loss, optimizer='adam')\n","\n","    # Load the generator network's weights\n","    try:\n","        generator.load_weights(\"generator.h5\")\n","    except Exception as e:\n","        print(f\"Error: {e}\")\n","\n","    z_i = np.random.normal(0, 1, size=(5000, z_shape))\n","\n","    y = np.random.randint(low=0, high=6, size=(5000,), dtype=np.int64)\n","    num_classes = len(set(y))\n","    y = np.reshape(np.array(y), [len(y), 1])\n","    y = to_categorical(y, num_classes=num_classes)\n","\n","    print(f'\\n\\n #################### TRAINING ENCODER ####################\\n\\n')\n","    for epoch in range(epochs):\n","        print(f\"\\nEpoch: {epoch + 1} out of {len(range(epochs))}\")\n","\n","        encoder_losses = []\n","\n","        number_of_batches = int(z_i.shape[0] / batch_size)\n","        for index in range(number_of_batches):\n","            print(f\"\\tBatch: {index + 1} out of {len(range(number_of_batches))}\\n\")\n","\n","            z_batch = z_i[index * batch_size:(index + 1) * batch_size]\n","            y_batch = y[index * batch_size:(index + 1) * batch_size]\n","\n","            generated_images = generator.predict_on_batch([z_batch, y_batch])\n","\n","            # Train the encoder model\n","            encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n","            print(f\"\\tEncoder loss: {encoder_loss}\")\n","\n","            encoder_losses.append(encoder_loss)\n","\n","        # Write the encoder loss to Tensorboard\n","        write_log(tensorboard, \"encoder_loss\", np.mean(encoder_losses), epoch)\n","\n","    # Save the encoder model\n","    encoder.save_weights(\"encoder.h5\")\n","\n","\"\"\"\n","Optimize the encoder and the generator network\n","\"\"\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vG_8Z2XY8XA7"},"source":["### Train GAN with Facial Recognition"]},{"cell_type":"code","metadata":{"id":"nvjsdjo_8cCP"},"source":["if TRAIN_GAN_WITH_FR:\n","\n","    # Load the encoder network\n","    encoder = build_encoder()\n","    encoder.load_weights(\"encoder.h5\")\n","\n","    # Load the generator network\n","    generator.load_weights(\"generator.h5\")\n","\n","    image_resizer = build_image_resizer()\n","    image_resizer.compile(loss=['binary_crossentropy'], optimizer='adam')\n","\n","    # Face recognition model\n","    fr_model = build_fr_model(input_shape=fr_image_shape)\n","    fr_model.compile(loss=['binary_crossentropy'], optimizer=\"adam\")\n","\n","    # Make the face recognition network as non-trainable\n","    fr_model.trainable = False\n","\n","    # Input layers\n","    input_image = Input(shape=(64, 64, 3))\n","    input_label = Input(shape=(6,))\n","\n","    # Use the encoder and the generator network\n","    latent0 = encoder(input_image)\n","    gen_images = generator([latent0, input_label])\n","\n","    # Resize images to the desired shape\n","    resized_images = Lambda(lambda x: K.resize_images(gen_images, height_factor=3, width_factor=3,\n","                                                      data_format='channels_last'))(gen_images)\n","    embeddings = fr_model(resized_images)\n","\n","    # Create a Keras model and specify the inputs and outputs for the network\n","    fr_adversarial_model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n","\n","    # Compile the model\n","    fr_adversarial_model.compile(loss=euclidean_distance_loss, optimizer=adversarial_optimizer)\n","\n","    print(f'\\n\\n #################### TRAINING GAN WITH FACE RECOGNITION ####################\\n\\n')\n","    for epoch in range(epochs):\n","        print(f\"\\nEpoch: {epoch + 1} out of {len(range(epochs))}\")\n","        reconstruction_losses = []\n","\n","        number_of_batches = int(len(loaded_images) / batch_size)\n","        for index in range(number_of_batches):\n","            print(f\"\\tBatch: {index + 1} out of {len(range(number_of_batches))}\\n\")\n","\n","            images_batch = loaded_images[index * batch_size:(index + 1) * batch_size]\n","            images_batch = images_batch / 127.5 - 1.0\n","            images_batch = images_batch.astype(np.float32)\n","\n","            y_batch = y[index * batch_size:(index + 1) * batch_size]\n","\n","            images_batch_resized = image_resizer.predict_on_batch(images_batch)\n","\n","            real_embeddings = fr_model.predict_on_batch(images_batch_resized)\n","\n","            reconstruction_loss = fr_adversarial_model.train_on_batch([images_batch, y_batch], real_embeddings)\n","\n","            print(f\"\\tReconstruction loss: {reconstruction_loss}\")\n","\n","            reconstruction_losses.append(reconstruction_loss)\n","\n","        # Write the reconstruction loss to Tensorboard\n","        write_log(tensorboard, \"reconstruction_loss\", np.mean(reconstruction_losses), epoch)\n","\n","        \"\"\"\n","        Generate images\n","        \"\"\"\n","        if epoch % 10 == 0:\n","            images_batch = loaded_images[0:batch_size]\n","            images_batch = images_batch / 127.5 - 1.0\n","            images_batch = images_batch.astype(np.float32)\n","\n","            y_batch = y[0:batch_size]\n","            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n","\n","            gen_images = generator.predict_on_batch([z_noise, y_batch])\n","\n","            for i, img in enumerate(gen_images[:5]):\n","                save_rgb_img(img, path=\"results/img_opt_{}_{}.png\".format(epoch, i))\n","\n","    # Save improved weights for both of the networks\n","    generator.save_weights(\"generator_optimized.h5\")\n","    encoder.save_weights(\"encoder_optimized.h5\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8qSgV4ZB8iKR"},"source":["## Visualizing the Logs"]},{"cell_type":"code","metadata":{"id":"yw0BVvTi8lbo"},"source":["%tensorboard --logdir=logs"],"execution_count":null,"outputs":[]}]}